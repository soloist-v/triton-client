use crate::error::Error;
use anyhow::Context;
use pyo3::types::PyAnyMethods;
use tonic::metadata::{AsciiMetadataValue, MetadataValue};
use tonic::service::Interceptor;
use tonic::transport::Channel;
use tonic::transport::channel::ClientTlsConfig;
use tonic::{Status, service::interceptor::InterceptedService};

use super::inference;
use super::inference::grpc_inference_service_client::GrpcInferenceServiceClient;

/// Adds bearer token auth to [`Client`]
#[derive(Clone)]
pub struct AuthInterceptor {
    token: Option<AsciiMetadataValue>,
}

impl Interceptor for AuthInterceptor {
    fn call(&mut self, mut request: tonic::Request<()>) -> Result<tonic::Request<()>, Status> {
        if let Some(token) = self.token.as_ref() {
            request
                .metadata_mut()
                .insert("authorization", token.clone());
        }
        Ok(request)
    }
}

impl AuthInterceptor {
    fn create(access_token: Option<&str>) -> Result<Self, Error> {
        if let Some(access_token) = access_token {
            let fmt_token: String = format!("Bearer {}", access_token);
            let token = Some(MetadataValue::try_from(fmt_token)?);
            Ok(AuthInterceptor { token })
        } else {
            Ok(AuthInterceptor { token: None })
        }
    }
}

/// Triton Client
#[pyo3::pyclass(module = "triton_client")]
#[derive(Debug, Clone)]
pub struct Client {
    /// Raw grpc client interfaces automatically generated by tonic
    ///
    /// Should not necessary to use this interface directly in most cases
    pub inner: GrpcInferenceServiceClient<InterceptedService<Channel, AuthInterceptor>>,
}

#[pyo3::pymethods]
impl Client {
    #[new]
    pub fn new(url: &str, access_token: Option<String>) -> Result<Self, Error> {
        let url = url.parse::<http::Uri>()?;
        let client = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async {
                let mut channel = Channel::builder(url);
                if access_token.is_some() {
                    channel = channel.tls_config(ClientTlsConfig::new())?;
                }
                let channel = channel.connect().await?;
                let client = GrpcInferenceServiceClient::with_interceptor(
                    channel,
                    AuthInterceptor::create(access_token.as_deref())?,
                );
                Ok::<_, Error>(client)
            })?;
        Ok(Client { inner: client })
    }

    #[doc = "Check liveness of the inference server."]
    #[inline(always)]
    pub fn server_live(&self) -> Result<inference::ServerLiveResponse, Error> {
        let req: inference::ServerLiveRequest = Default::default();
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async { inner.server_live(tonic::Request::new(req)).await })?;
        Ok(response.into_inner())
    }

    #[doc = "Check readiness of the inference server."]
    #[inline(always)]
    pub fn server_ready(&self) -> Result<inference::ServerReadyResponse, Error> {
        let req: inference::ServerReadyRequest = Default::default();
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async { inner.server_ready(tonic::Request::new(req)).await })?;
        Ok(response.into_inner())
    }
    #[doc = "Check readiness of a model in the inference server."]
    #[inline(always)]
    pub fn model_ready(
        &self,
        req: inference::ModelReadyRequest,
    ) -> Result<inference::ModelReadyResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async { inner.model_ready(tonic::Request::new(req)).await })?;
        Ok(response.into_inner())
    }
    #[doc = "Get server metadata."]
    #[inline(always)]
    pub fn server_metadata(&self) -> Result<inference::ServerMetadataResponse, Error> {
        let req: inference::ServerMetadataRequest = Default::default();
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async { inner.server_metadata(tonic::Request::new(req)).await })?;
        Ok(response.into_inner())
    }
    #[doc = "Get model metadata."]
    #[inline(always)]
    pub fn model_metadata(
        &self,
        req: inference::ModelMetadataRequest,
    ) -> Result<inference::ModelMetadataResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async { inner.model_metadata(tonic::Request::new(req)).await })?;
        Ok(response.into_inner())
    }
    #[doc = "Perform inference using a specific model."]
    #[inline(always)]
    pub fn model_infer(
        &self,
        req: pyo3::Bound<'_, pyo3::PyAny>,
    ) -> Result<inference::ModelInferResponse, Error> {
        let req = req.extract::<inference::ModelInferRequest>().map_err(Error::msg)?;
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async { inner.model_infer(tonic::Request::new(req)).await })?;
        Ok(response.into_inner())
    }
    #[doc = "Get model configuration."]
    #[inline(always)]
    pub fn model_config(
        &self,
        req: inference::ModelConfigRequest,
    ) -> Result<inference::ModelConfigResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async { inner.model_config(tonic::Request::new(req)).await })?;
        Ok(response.into_inner())
    }
    #[doc = "Get the cumulative inference statistics for a model."]
    #[inline(always)]
    pub fn model_statistics(
        &self,
        req: inference::ModelStatisticsRequest,
    ) -> Result<inference::ModelStatisticsResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async { inner.model_statistics(tonic::Request::new(req)).await })?;
        Ok(response.into_inner())
    }
    #[doc = "Get the index of model repository contents."]
    #[inline(always)]
    pub fn repository_index(
        &self,
        req: inference::RepositoryIndexRequest,
    ) -> Result<inference::RepositoryIndexResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async { inner.repository_index(tonic::Request::new(req)).await })?;
        Ok(response.into_inner())
    }
    #[doc = "Load or reload a model from a repository."]
    #[inline(always)]
    pub fn repository_model_load(
        &self,
        req: inference::RepositoryModelLoadRequest,
    ) -> Result<inference::RepositoryModelLoadResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async { inner.repository_model_load(tonic::Request::new(req)).await })?;
        Ok(response.into_inner())
    }
    #[doc = "Unload a model."]
    #[inline(always)]
    pub fn repository_model_unload(
        &self,
        req: inference::RepositoryModelUnloadRequest,
    ) -> Result<inference::RepositoryModelUnloadResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async {
                inner
                    .repository_model_unload(tonic::Request::new(req))
                    .await
            })?;
        Ok(response.into_inner())
    }
    #[doc = "Get the status of all registered system-shared-memory regions."]
    #[inline(always)]
    pub fn system_shared_memory_status(
        &self,
        req: inference::SystemSharedMemoryStatusRequest,
    ) -> Result<inference::SystemSharedMemoryStatusResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async {
                inner
                    .system_shared_memory_status(tonic::Request::new(req))
                    .await
            })?;
        Ok(response.into_inner())
    }
    #[doc = "Register a system-shared-memory region."]
    #[inline(always)]
    pub fn system_shared_memory_register(
        &self,
        req: inference::SystemSharedMemoryRegisterRequest,
    ) -> Result<inference::SystemSharedMemoryRegisterResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async {
                inner
                    .system_shared_memory_register(tonic::Request::new(req))
                    .await
            })?;
        Ok(response.into_inner())
    }
    #[doc = "Unregister a system-shared-memory region."]
    #[inline(always)]
    pub fn system_shared_memory_unregister(
        &self,
        req: inference::SystemSharedMemoryUnregisterRequest,
    ) -> Result<inference::SystemSharedMemoryUnregisterResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async {
                inner
                    .system_shared_memory_unregister(tonic::Request::new(req))
                    .await
            })?;
        Ok(response.into_inner())
    }
    #[doc = "Get the status of all registered CUDA-shared-memory regions."]
    #[inline(always)]
    pub fn cuda_shared_memory_status(
        &self,
        req: inference::CudaSharedMemoryStatusRequest,
    ) -> Result<inference::CudaSharedMemoryStatusResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async {
                inner
                    .cuda_shared_memory_status(tonic::Request::new(req))
                    .await
            })?;
        Ok(response.into_inner())
    }
    #[doc = "Register a CUDA-shared-memory region."]
    #[inline(always)]
    pub fn cuda_shared_memory_register(
        &self,
        req: inference::CudaSharedMemoryRegisterRequest,
    ) -> Result<inference::CudaSharedMemoryRegisterResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async {
                inner
                    .cuda_shared_memory_register(tonic::Request::new(req))
                    .await
            })?;
        Ok(response.into_inner())
    }
    #[doc = "Unregister a CUDA-shared-memory region."]
    #[inline(always)]
    pub fn cuda_shared_memory_unregister(
        &self,
        req: inference::CudaSharedMemoryUnregisterRequest,
    ) -> Result<inference::CudaSharedMemoryUnregisterResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async {
                inner
                    .cuda_shared_memory_unregister(tonic::Request::new(req))
                    .await
            })?;
        Ok(response.into_inner())
    }
    #[doc = "Update and get the trace setting of the Triton server."]
    #[inline(always)]
    pub fn trace_setting(
        &self,
        req: inference::TraceSettingRequest,
    ) -> Result<inference::TraceSettingResponse, Error> {
        let mut inner = self.inner.clone();
        let response = crate::TOKIO_RT
            .get()
            .context("failed to get tokio runtime")?
            .block_on(async { inner.trace_setting(tonic::Request::new(req)).await })?;
        Ok(response.into_inner())
    }
}
